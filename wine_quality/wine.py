# -*- coding: utf-8 -*-
"""Desenvolvendo pipelines.ipynb

Criar ambiente virtual
conda create -n venv

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q9U0T89jFTOjDYjurgCY6r6Tj5zByYu7

# Desenvolvendo pipelines
>
> ## Previsão da qualidade do vinho
>
> Informações sobre o dataset:
>
>Variáveis ​​de entrada:
* acidez fixa (fixed acidity)
* acidez volátil (volatile acidity)
* ácido cítrico (citric acid)
* açúcar residual (residual sugar)
* cloretos (chlorides)
* dióxido de enxofre livre (free sulfur dioxide)
* dióxido de enxofre total (total sulfur dioxide)
* densidade (density)
* pH
* sulfatos (sulphates)
* álcool (alcohol)
>
> Variável de saída (target):
* qualidade (quality) -> pontuação entre 0 e 10

Arquivo: winequalityN.csv

#### Importação das bibliotecas
"""

import pandas as pd
import numpy as np

#Visualização
import seaborn as sns
import matplotlib.pyplot as plt

#Pre-processamento
from sklearn.preprocessing import StandardScaler,OneHotEncoder,FunctionTransformer
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

#Divisão em treino e teste
from sklearn.model_selection import train_test_split

#Modelo
from sklearn.tree import DecisionTreeClassifier

#Hiperparâmetros
from sklearn.model_selection import GridSearchCV

pd.__version__

"""#### Análise do dataset"""

df=pd.read_csv("winequalityN.csv")

df.shape

df.info()

df.describe()

df.isnull().sum()

len(df)-len(df.drop_duplicates())

"""## EDA"""

df.hist(bins=25,figsize=(20,20))

sns.countplot(df['type'])

correlacao=df.corr()

plt.figure(figsize=(20,20))
sns.heatmap(correlacao,annot=True)

"""## Pre-processamento"""

df=df.drop_duplicates(keep="first")

df.shape

sns.countplot(df['quality'])

df['quality']=np.where(df['quality']>=6,1,0)

sns.countplot(df['quality'])

X=df.drop(['quality'],axis=1)

y=df.quality

X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,test_size=0.2)

model_pipeline =Pipeline(
    steps=[
           ('encoder', ColumnTransformer(
               [
                ('encoder_type', OneHotEncoder(drop='first'),['type'])
                ]
              )
           ),
           ('imputer', SimpleImputer(strategy='mean',fill_value=np.nan)),
           ('classifier',DecisionTreeClassifier())

    ]
)

model_pipeline.fit(X_train,y_train)

model_pipeline.score(X_train,y_train)

model_pipeline.score(X_test,y_test)

model_pipeline.get_params()

params={
 'classifier__criterion': ['gini','entropy'],
 'classifier__max_depth': range(5,10),
 'classifier__min_samples_leaf': range(1,5),
 'classifier__min_samples_split': (2,5)
}

grid=GridSearchCV(model_pipeline, params, cv=5)

grid.fit(X_train,y_train)

grid.score(X_train,y_train)

grid.score(X_test,y_test)

grid.get_params()

best_piepeline=grid.best_estimator_

